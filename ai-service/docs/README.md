# Sketch Recognition AI Service

This document provides an overview of the AI service for the sketch recognition game, including the data processing, model architecture, training process, and results.

---

## ğŸ“Š Project Overview

We've built a sketch recognition system using the Quick Draw dataset, initially focusing on 5 categories: airplane, apple, bicycle, cat, and house. The system has been enhanced to now recognize 14 categories using a MobileNetV2-based neural network with transfer learning to classify hand-drawn sketches.

---

## â³ Implementation Timeline

1. **Environment Setup** - Configured Python virtual environment with TensorFlow and all necessary dependencies.
2. **Initial Dataset Processing** - Downloaded and processed 5,000 sketches per category (25,000 total) for 5 categories.
3. **Model Architecture** - Implemented a MobileNetV2-based transfer learning model.
4. **Phase 1 Training** - Trained classification layers with base frozen.
5. **Phase 2 Training** - Fine-tuned top layers of the MobileNetV2 base.
6. **Dataset Expansion** - Extended dataset to include 14 categories for improved recognition capabilities.
7. **Enhanced Model Training** - Retrained the model with expanded dataset.

---

## ğŸ“ Data Processing

### Initial Dataset (5 Categories)
Steps:
1. Downloaded raw sketches for 5 categories (5,000 samples each).
2. Rendered stroke data to images with proper padding and scaling.
3. Normalized images to match MobileNetV2 input requirements.
4. Split data into training (70%), validation (15%), and test (15%) sets.

**Initial Dataset Statistics:**
- Categories: airplane, apple, bicycle, cat, house
- Training samples: 17,500 (3,500 per category)
- Validation samples: 3,750 (750 per category)
- Test samples: 3,750 (750 per category)

### Expanded Dataset (14 Categories)
Steps:
1. Added 9 new categories to the existing 5 categories.
2. Processed the new categories using the same methodology.
3. Maintained consistent preprocessing for all categories.

**Expanded Dataset Statistics:**
- Categories: airplane, apple, bicycle, car, cat, chair, clock, dog, face, fish, house, star, tree, umbrella
- Training samples: 51,122
- Validation samples: 11,788
- Test samples: 11,785

---

## ğŸŒ Model Architecture

Using transfer learning with MobileNetV2:

1. Input Layer: 28x28x1 grayscale images
2. Channel Expansion: Convert to 28x28x3
3. Resize to 96x96x3
4. MobileNetV2 Base (pre-trained on ImageNet)
5. Custom Classification Head:
   - Dropout (0.2)
   - Dense Layer (256, ReLU)
   - Batch Normalization
   - Dropout (0.5)
   - Output Layer (5 classes initially, extended to 14 classes)

**Training Strategy:**
- Phase 1: Train only the classification head.
- Phase 2: Fine-tune top 50 layers of MobileNetV2.

---

## ğŸ† Training Results

### Initial Model (5 Categories)

#### Phase 1: Training Classification Head
- **Epochs**: 10
- **Batch Size**: 64
- **Learning Rate**: 0.001 (reduced to 0.0002)
- **Data Augmentation**: Enabled
- **Training Time**: ~27 minutes

##### Metrics:
- Top-1 Accuracy: 46.03%
- Top-3 Accuracy: 92.85%
- Loss: 1.1183

#### Phase 2: Fine-tuning the Model
- **Epochs**: 20
- **Batch Size**: 64
- **Learning Rate**: 0.0001
- **Data Augmentation**: Enabled
- **Training Time**: ~64 minutes

##### Metrics:
- Top-1 Accuracy: 70.48%
- Top-3 Accuracy: 96.00%
- Loss: 0.8411

#### Accuracy Progress:
- Validation accuracy improved from 20.00% to 70.21% across 20 epochs.

#### Improvement Summary:
- Top-1 Accuracy: +24.45%
- Top-3 Accuracy: +3.15%
- Loss Reduction: -0.2772

### Expanded Model (14 Categories)

#### Phase 1: Training Classification Head
- **Epochs**: 10
- **Batch Size**: 64
- **Learning Rate**: 0.001
- **Data Augmentation**: Enabled
- **Training Time**: ~65 minutes (3919.99 seconds)

##### Metrics:
- Top-1 Accuracy: 35.96%
- Top-3 Accuracy: 64.73%
- Loss: 1.9484

#### Phase 2: Fine-tuning the Model
- **Epochs**: 20
- **Batch Size**: 64
- **Learning Rate**: 0.0001
- **Data Augmentation**: Enabled
- **Training Time**: ~159 minutes (9534.29 seconds)

##### Metrics:
- Top-1 Accuracy: 55.22%
- Top-3 Accuracy: 82.71%
- Loss: 1.4080

#### Accuracy Progress:
- Validation accuracy improved from 5.54% to 54.16% across 20 epochs.

#### Improvement Summary:
- Top-1 Accuracy: +19.26% from Phase 1 to Phase 2
- Top-3 Accuracy: +17.98% from Phase 1 to Phase 2
- Loss Reduction: -0.5404 from Phase 1 to Phase 2

---

## ğŸ” Model Analysis

### Initial Model (5 Categories)
The 5-category model achieved:
- **70.48%** Top-1 accuracy
- **96.00%** Top-3 accuracy

### Expanded Model (14 Categories)
The expanded 14-category model achieves:
- **55.22%** Top-1 accuracy
- **82.71%** Top-3 accuracy

### Performance Comparison
While the expanded model has lower absolute accuracy metrics, this is expected due to:
- Increased classification complexity (14 classes vs 5 classes)
- More potential for confusion between visually similar categories
- Wider variety of drawing styles to recognize

Despite the increased challenge, the expanded model provides much greater utility with nearly 3x the recognition capabilities.

### Considerations:
- High variability in sketching styles
- Limited 28x28 pixel resolution
- Similar-looking objects across categories
- Training with 14 classes provides broader recognition capabilities for the game

Despite these challenges, both models show strong generalization and robustness.

---

## âœ… Next Steps

### 1. API Integration
- Implement Flask API for real-time recognition.

### 2. Frontend Integration
- Connect model to game's frontend UI.

### 3. Model Optimization
Convert to TensorFlow Lite with quantization:
```bash
python scripts/train_model.py --model-type mobilenet --convert-tflite --quantize
```

### 4. Expand Categories
- Add more Quick Draw categories for broader recognition.

### 5. Performance Evaluation
Generate confusion matrix and classification report:
```bash
python scripts/train_model.py --model-type mobilenet --phase 2 --confusion-matrix --learning-rate 0.0001
```

---

## ğŸ“‚ File & Directory Structure

```
ai-service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”‚   â”œâ”€â”€ data_processor.py
â”‚   â”‚   â””â”€â”€ model_builder.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ quickdraw/  # Contains .h5 and .json model files
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ model_utils.py
â”‚       â””â”€â”€ visualization.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/            # NDJSON files
â”‚   â””â”€â”€ processed/      # 28x28 PNGs
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ SETUP.md
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ model_training.ipynb
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_dataset.py
â”‚   â”œâ”€â”€ process_dataset.py
â”‚   â””â”€â”€ train_model.py
â””â”€â”€ requirements.txt
```

---

## ğŸš€ Conclusion

- The MobileNetV2-based model demonstrates strong learning capacity from low-res sketches.
- Phase 2 fine-tuning significantly enhanced performance.
- With real-time API integration and category expansion, the sketch recognition game is poised for high engagement and scalability.

The modular architecture supports future experimentation and deployment strategies.


## ğŸ“ˆ Latest Training Results (May 2025)

### Updated Dataset

- Expanded to 14 classes: airplane, apple, bicycle, car, cat, chair, clock, dog, face, fish, house, star, tree, umbrella
- Processed images: 51,122 training, 11,788 validation, 11,785 test

### Phase 1 Training (May 2025)
- Command:
   ```
   python scripts/train_model.py --model-type mobilenet --phase 1 --epochs 10 --batch-size 64 --learning-rate 0.001 
   --augmentation
   ```
- Hardware: CPU only
- Duration: 65 minutes (3919.99 seconds)
- Best validation accuracy: 36.13% (Epoch 8)
- Final test accuracy: 35.96%
- Test top-3 accuracy: 64.73%

### Phase 2 Fine-tuning (May 2025)

- Command:
   ```
   python scripts/train_model.py --model-type mobilenet --phase 2 --epochs 20 --batch-size 64 --learning-rate 0.0001 --augmentation
   ```
- Hardware: CPU only
- Duration: 159 minutes (9534.29 seconds)
- Best validation accuracy: 54.16% (Epoch 20)
- Final test accuracy: 55.22%
- Test top-3 accuracy: 82.71%

### Observations
- The model showed steady improvement throughout phase 2 training
- Top-1 accuracy improved by 19.26 percentage points from phase 1 to phase 2
- Top-3 accuracy improved by 17.98 percentage points, indicating good representation learning
- The model is now trained on a broader set of categories, making it more versatile for the game

### Model Evolution
- Initial Model (5 Categories): Higher accuracy on fewer categories
- Expanded Model (14 Categories): Slightly lower accuracy but much broader recognition capabilities
- The tradeoff between accuracy and category coverage is expected and beneficial for game experience

### Model Files
The latest trained models are saved at:

- Phase 1: app/models/quickdraw/quickdraw_model_mobilenet_phase1_20250504_212529.h5
- Phase 2: app/models/quickdraw/quickdraw_model_mobilenet_phase2_20250504_223625.h5

Both models include corresponding metadata JSON files with the same naming convention. 