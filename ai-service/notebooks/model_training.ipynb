{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ab2fec8",
   "metadata": {},
   "source": [
    "# Quick Draw Sketch Recognition Model Training\n",
    "\n",
    "This notebook demonstrates the training process for the sketch recognition model using the processed Quick Draw dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad21ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Add parent directory to path to import from app modules\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a730129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom modules\n",
    "from app.services.data_loader_processed import ProcessedDataLoader\n",
    "from app.services.model_builder import QuickDrawModelBuilder\n",
    "from app.utils.visualization import plot_confusion_matrix, visualize_model_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076e039b",
   "metadata": {},
   "source": [
    "## 1. Define Paths and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fa3065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "base_dir = Path('..')\n",
    "data_dir = base_dir / \"app\" / \"datasets\" / \"processed\"\n",
    "model_dir = base_dir / \"app\" / \"models\" / \"quickdraw\"\n",
    "\n",
    "# Ensure directories exist\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Configuration parameters\n",
    "config = {\n",
    "    'model_type': 'advanced',  # 'simple', 'advanced', or 'mobilenet'\n",
    "    'batch_size': 64,\n",
    "    'epochs': 20,\n",
    "    'learning_rate': 0.001,\n",
    "    'max_per_class': None,  # Limit samples per class (None for all)\n",
    "    'data_augmentation': True\n",
    "}\n",
    "\n",
    "# Show configuration\n",
    "for key, value in config.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92708ae",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb7784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed dataset\n",
    "data_loader = ProcessedDataLoader(data_dir)\n",
    "\n",
    "# Get class names\n",
    "class_names = data_loader.class_names\n",
    "print(f\"Found {len(class_names)} classes: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e36ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators with augmentation\n",
    "train_generator, val_generator, test_generator, _ = data_loader.get_data_generators(\n",
    "    batch_size=config['batch_size'],\n",
    "    augmentation=config['data_augmentation'],\n",
    "    max_per_class=config['max_per_class']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca75cccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a small sample of images to visualize\n",
    "dataset = data_loader.load_dataset(max_per_class=100)\n",
    "X_train, y_train, _ = dataset['train']\n",
    "X_val, y_val, _ = dataset['validation']\n",
    "X_test, y_test, _ = dataset['test']\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efd9d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some training examples\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(15):  # Display 15 images\n",
    "    plt.subplot(3, 5, i+1)\n",
    "    img = X_train[i]\n",
    "    if img.shape[-1] == 1:  # Grayscale\n",
    "        plt.imshow(img.reshape(img.shape[0], img.shape[1]), cmap='gray')\n",
    "    else:  # RGB\n",
    "        plt.imshow(img)\n",
    "    class_idx = np.argmax(y_train[i])\n",
    "    plt.title(class_names[class_idx])\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c24c00f",
   "metadata": {},
   "source": [
    "## 3. Build and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafb5c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"Using {len(gpus)} GPU(s)\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"  {gpu}\")\n",
    "    # Configure memory growth to prevent OOM errors\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error configuring GPU: {e}\")\n",
    "else:\n",
    "    print(\"No GPU found, using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f66a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model builder\n",
    "model_builder = QuickDrawModelBuilder()\n",
    "\n",
    "# Build the selected model architecture\n",
    "if config['model_type'] == 'simple':\n",
    "    model = model_builder.build_simple_cnn(len(class_names))\n",
    "elif config['model_type'] == 'advanced':\n",
    "    model = model_builder.build_advanced_cnn(len(class_names))\n",
    "elif config['model_type'] == 'mobilenet':\n",
    "    model = model_builder.build_mobilenet_based(len(class_names))\n",
    "else:\n",
    "    raise ValueError(f\"Unknown model type: {config['model_type']}\")\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b8b083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up callbacks\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_filename = f\"quickdraw_model_{config['model_type']}_{timestamp}.h5\"\n",
    "model_path = model_dir / model_filename\n",
    "\n",
    "# TensorBoard callback\n",
    "log_dir = model_dir / \"logs\" / f\"{config['model_type']}_{timestamp}\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1\n",
    ")\n",
    "\n",
    "# ModelCheckpoint callback\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=str(model_path),\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Reduce learning rate on plateau\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    min_lr=0.00001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks_list = [tensorboard_callback, checkpoint_callback, early_stopping, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b56630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "start_time = time.time()\n",
    "history = model_builder.train(\n",
    "    train_generator,\n",
    "    val_generator,\n",
    "    epochs=config['epochs'],\n",
    "    batch_size=config['batch_size'],\n",
    "    callbacks_list=callbacks_list\n",
    ")\n",
    "\n",
    "# Calculate training time\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Training completed in {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08882eea",
   "metadata": {},
   "source": [
    "## 4. Evaluate and Visualize Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64d95b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "history_plot_path = model_dir / f\"training_history_{config['model_type']}_{timestamp}.png\"\n",
    "model_builder.plot_training_history(save_path=str(history_plot_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf027b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "print(\"Evaluating model on test data...\")\n",
    "metrics = model_builder.evaluate(test_generator)\n",
    "print(f\"Test accuracy: {metrics.get('accuracy', 0):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a2193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63998da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "plt.figure(figsize=(12, 10))\n",
    "plot_confusion_matrix(cm, class_names, normalize=True)\n",
    "plt.savefig(model_dir / f\"confusion_matrix_{config['model_type']}_{timestamp}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50c99c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some predictions\n",
    "fig = visualize_model_predictions(model, X_test, y_test, class_names, num_images=8)\n",
    "plt.savefig(model_dir / f\"prediction_examples_{config['model_type']}_{timestamp}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c28132",
   "metadata": {},
   "source": [
    "## 5. Save the Model with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc2e78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create metadata\n",
    "metadata = {\n",
    "    'input_shape': model.input_shape[1:],\n",
    "    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'num_classes': len(class_names),\n",
    "    'class_names': class_names,\n",
    "    'model_type': config['model_type'],\n",
    "    'config': config,\n",
    "    'metrics': {\n",
    "        'accuracy': float(metrics.get('accuracy', 0)),\n",
    "        'loss': float(metrics.get('loss', 0))\n",
    "    },\n",
    "    'training_time_seconds': training_time\n",
    "}\n",
    "\n",
    "# Add training history\n",
    "if model_builder.history is not None:\n",
    "    metadata['training_history'] = {\n",
    "        'accuracy': float(max(model_builder.history.get('accuracy', [0]))),\n",
    "        'val_accuracy': float(max(model_builder.history.get('val_accuracy', [0]))),\n",
    "        'loss': float(min(model_builder.history.get('loss', [0]))),\n",
    "        'val_loss': float(min(model_builder.history.get('val_loss', [0]))),\n",
    "        'epochs_trained': len(model_builder.history.get('accuracy', [])),\n",
    "    }\n",
    "\n",
    "# Save model with metadata\n",
    "result = model_builder.save_model(str(model_path), class_names=class_names)\n",
    "print(f\"Model saved to {result['model_path']}\")\n",
    "print(f\"Metadata saved to {result['metadata_path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e626cf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert model to TensorFlow Lite format for inference\n",
    "from app.utils.model_utils import convert_model_to_tflite\n",
    "\n",
    "tflite_path = str(model_path).replace('.h5', '.tflite')\n",
    "tflite_file = convert_model_to_tflite(model, tflite_path, quantize=True)\n",
    "print(f\"TFLite model saved to {tflite_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113b1d83",
   "metadata": {},
   "source": [
    "## 6. Model Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af29fec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a single image and perform inference\n",
    "from app.utils.model_utils import load_model_with_metadata\n",
    "\n",
    "# Select a random test image\n",
    "test_idx = np.random.randint(0, len(X_test))\n",
    "test_image = X_test[test_idx]\n",
    "true_label = np.argmax(y_test[test_idx])\n",
    "\n",
    "# Reshape for model input (add batch dimension)\n",
    "input_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "# Make prediction\n",
    "predictions = model.predict(input_image)\n",
    "predicted_class = np.argmax(predictions[0])\n",
    "\n",
    "# Show the image and prediction\n",
    "plt.figure(figsize=(6, 6))\n",
    "if test_image.shape[-1] == 1:  # Grayscale\n",
    "    plt.imshow(test_image.reshape(test_image.shape[0], test_image.shape[1]), cmap='gray')\n",
    "else:  # RGB\n",
    "    plt.imshow(test_image)\n",
    "plt.title(f\"True: {class_names[true_label]}\\nPredicted: {class_names[predicted_class]}\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Show top 3 predictions\n",
    "top_indices = predictions[0].argsort()[-3:][::-1]\n",
    "print(\"Top 3 predictions:\")\n",
    "for i, idx in enumerate(top_indices):\n",
    "    print(f\"{i+1}. {class_names[idx]}: {predictions[0][idx]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73449579",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "The model training process is complete. Here's a summary of what we've accomplished:\n",
    "\n",
    "1. Loaded and visualized the processed Quick Draw dataset\n",
    "2. Built and trained a CNN model for sketch recognition\n",
    "3. Evaluated the model performance\n",
    "4. Saved the trained model with metadata for inference\n",
    "5. Converted the model to TensorFlow Lite format for efficient deployment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
